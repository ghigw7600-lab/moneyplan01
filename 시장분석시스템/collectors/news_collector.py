# -*- coding: utf-8 -*-
"""
ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
NewsAPI ì‚¬ìš© (ë¬´ë£Œ: í•˜ë£¨ 100 ìš”ì²­)
"""

import requests
from datetime import datetime, timedelta
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import NEWS_API_KEY


class NewsCollector:
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ê¸°"""

    def __init__(self, api_key=NEWS_API_KEY):
        self.api_key = api_key
        self.base_url = "https://newsapi.org/v2"

    def get_news(self, query, days=7, language="ko", page_size=20):
        """
        ë‰´ìŠ¤ ê²€ìƒ‰

        Args:
            query (str): ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: "ì‚¼ì„±ì „ì", "ë¹„íŠ¸ì½”ì¸")
            days (int): ê²€ìƒ‰ ê¸°ê°„ (ì¼)
            language (str): ì–¸ì–´ (ko, en)
            page_size (int): ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 100)

        Returns:
            list: ë‰´ìŠ¤ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        """
        if not self.api_key:
            print("âš ï¸ NEWS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ config.pyì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            print("ğŸ’¡ https://newsapi.org ì—ì„œ ë¬´ë£Œë¡œ ë°œê¸‰ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return []

        try:
            print(f"ğŸ“° '{query}' ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")

            # ë‚ ì§œ ê³„ì‚°
            from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')

            url = f"{self.base_url}/everything"
            params = {
                'q': query,
                'from': from_date,
                'language': language,
                'sortBy': 'publishedAt',
                'pageSize': page_size,
                'apiKey': self.api_key
            }

            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            if data.get('status') != 'ok':
                print(f"âŒ API ì—ëŸ¬: {data.get('message')}")
                return []

            articles = data.get('articles', [])
            print(f"âœ… ë‰´ìŠ¤ {len(articles)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

            # ë°ì´í„° ì •ì œ
            news_list = []
            for article in articles:
                news_list.append({
                    'ì œëª©': article.get('title'),
                    'ì„¤ëª…': article.get('description'),
                    'ë‚´ìš©': article.get('content'),
                    'ì¶œì²˜': article.get('source', {}).get('name'),
                    'URL': article.get('url'),
                    'ê²Œì‹œì¼': article.get('publishedAt'),
                    'ì´ë¯¸ì§€': article.get('urlToImage')
                })

            return news_list

        except requests.exceptions.RequestException as e:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return []
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: {str(e)}")
            return []

    def get_top_headlines(self, category=None, country="kr"):
        """
        í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ì¡°íšŒ

        Args:
            category (str): ì¹´í…Œê³ ë¦¬ (business, technology, etc.)
            country (str): êµ­ê°€ ì½”ë“œ (kr, us)

        Returns:
            list: í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        if not self.api_key:
            print("âš ï¸ NEWS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        try:
            url = f"{self.base_url}/top-headlines"
            params = {
                'country': country,
                'apiKey': self.api_key
            }

            if category:
                params['category'] = category

            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()
            articles = data.get('articles', [])

            news_list = []
            for article in articles:
                news_list.append({
                    'ì œëª©': article.get('title'),
                    'ì„¤ëª…': article.get('description'),
                    'ì¶œì²˜': article.get('source', {}).get('name'),
                    'URL': article.get('url'),
                    'ê²Œì‹œì¼': article.get('publishedAt')
                })

            return news_list

        except Exception as e:
            print(f"âŒ í—¤ë“œë¼ì¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []

    def get_market_news(self, days=7):
        """
        ì‹œì¥ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì—¬ëŸ¬ í‚¤ì›Œë“œ í†µí•©)

        Returns:
            dict: í‚¤ì›Œë“œë³„ ë‰´ìŠ¤
        """
        keywords = {
            'ì£¼ì‹': 'ì£¼ì‹ OR ì¦ì‹œ OR ì½”ìŠ¤í”¼ OR ë‚˜ìŠ¤ë‹¥',
            'ì•”í˜¸í™”í': 'ë¹„íŠ¸ì½”ì¸ OR ì•”í˜¸í™”í OR ê°€ìƒí™”í',
            'ê²½ì œ': 'ê²½ì œ OR ê¸ˆë¦¬ OR í™˜ìœ¨',
            'ê¸°ìˆ ': 'ê¸°ìˆ ì£¼ OR IT OR ë°˜ë„ì²´'
        }

        all_news = {}
        for category, query in keywords.items():
            news = self.get_news(query, days=days, page_size=10)
            all_news[category] = news

        return all_news


# ê°„ë‹¨í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ (API í‚¤ ì—†ì„ ë•Œ ëŒ€ì•ˆ)
class SimpleNewsCollector:
    """API í‚¤ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""

    def get_dummy_news(self, query, count=5):
        """
        í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë‰´ìŠ¤ ìƒì„±
        ì‹¤ì œë¡œëŠ” í¬ë¡¤ë§ì´ë‚˜ RSS í”¼ë“œ ì‚¬ìš© ê°€ëŠ¥
        """
        print(f"âš ï¸ API í‚¤ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

        news_list = []
        for i in range(count):
            news_list.append({
                'ì œëª©': f'[í…ŒìŠ¤íŠ¸] {query} ê´€ë ¨ ë‰´ìŠ¤ {i+1}',
                'ì„¤ëª…': f'{query}ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ì…ë‹ˆë‹¤.',
                'ì¶œì²˜': 'í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤',
                'URL': 'https://example.com',
                'ê²Œì‹œì¼': datetime.now().isoformat()
            })

        return news_list


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    # API í‚¤ê°€ ìˆìœ¼ë©´ NewsCollector, ì—†ìœ¼ë©´ SimpleNewsCollector ì‚¬ìš©
    if NEWS_API_KEY:
        collector = NewsCollector(NEWS_API_KEY)

        # ì‚¼ì„±ì „ì ë‰´ìŠ¤ ê²€ìƒ‰
        print("\n=== ì‚¼ì„±ì „ì ë‰´ìŠ¤ ===")
        news = collector.get_news("ì‚¼ì„±ì „ì", days=7)
        for i, article in enumerate(news[:3], 1):
            print(f"\n{i}. {article['ì œëª©']}")
            print(f"   ì¶œì²˜: {article['ì¶œì²˜']} | {article['ê²Œì‹œì¼']}")
            print(f"   {article['ì„¤ëª…'][:100]}...")

        # ë¹„íŠ¸ì½”ì¸ ë‰´ìŠ¤ ê²€ìƒ‰
        print("\n\n=== ë¹„íŠ¸ì½”ì¸ ë‰´ìŠ¤ ===")
        news = collector.get_news("ë¹„íŠ¸ì½”ì¸", days=7)
        for i, article in enumerate(news[:3], 1):
            print(f"\n{i}. {article['ì œëª©']}")
            print(f"   ì¶œì²˜: {article['ì¶œì²˜']}")

    else:
        print("\nâš ï¸ NEWS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n")

        collector = SimpleNewsCollector()
        news = collector.get_dummy_news("ì‚¼ì„±ì „ì")
        for article in news:
            print(f"- {article['ì œëª©']}")
