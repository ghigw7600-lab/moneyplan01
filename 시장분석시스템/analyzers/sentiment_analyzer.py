# -*- coding: utf-8 -*-
"""
AI ê°ì„± ë¶„ì„ ëª¨ë“ˆ
ë‰´ìŠ¤ ì œëª©/ë‚´ìš©ì˜ ê¸ì •/ë¶€ì • ê°ì„± ë¶„ì„
"""

import re
from collections import Counter


class SentimentAnalyzer:
    """ê°ì„± ë¶„ì„ê¸° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""

    def __init__(self):
        # ê¸ì • í‚¤ì›Œë“œ (ëŒ€í­ í™•ìž¥ - ê¸ˆìœµ ìš©ì–´)
        self.positive_keywords = [
            # ê¸°ì¡´
            'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ìž¬', 'ì„±ìž¥', 'ì¦ê°€', 'ê°œì„ ', 'í™•ëŒ€', 'ëŒíŒŒ', 'ìµœê³ ',
            'ê°•ì„¸', 'ë°˜ë“±', 'íšŒë³µ', 'ê¸ì •', 'ìˆ˜í˜œ', 'ê¸°ëŒ€', 'ì „ë§', 'íˆ¬ìž', 'í˜¸í™©',
            'ì‹¤ì ', 'ì´ìµ', 'ë°°ë‹¹', 'ì‹ ê³ ê°€', 'í”ŒëŸ¬ìŠ¤', 'ìƒí–¥', 'ë§¤ìˆ˜', 'ì¶”ì²œ',
            # ì¶”ê°€ - ì‹¤ì /ìž¬ë¬´
            'í‘ìž', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ë§¤ì¶œì¦ê°€', 'ìˆ˜ìµì„±', 'ì´ìµë¥ ', 'ìžì‚°ì¦ê°€',
            'ë¶€ì±„ê°ì†Œ', 'ìž¬ë¬´ê°œì„ ', 'í˜„ê¸ˆíë¦„', 'ROE', 'ROI', 'ë§ˆì§„í™•ëŒ€',
            # ì¶”ê°€ - ì‹œìž¥/ê¸°ìˆ 
            'í˜ì‹ ', 'ê¸°ìˆ ë ¥', 'íŠ¹í—ˆ', 'ì‹ ì œí’ˆ', 'ì¶œì‹œ', 'ë¡ ì¹­', 'ê³„ì•½', 'ìˆ˜ì£¼',
            'íŒŒíŠ¸ë„ˆì‹­', 'ì œíœ´', 'MOU', 'í˜‘ë ¥', 'ì§„ì¶œ', 'í™•ìž¥', 'ì¸ìˆ˜', 'í•©ë³‘',
            # ì¶”ê°€ - ì „ë§/ë¶„ì„
            'ëª©í‘œê°€ìƒí–¥', 'ë ˆì´íŒ…ìƒí–¥', 'BUY', 'ê°•ë ¥ë§¤ìˆ˜', 'ì ê·¹ë§¤ìˆ˜', 'ë¹„ì¤‘í™•ëŒ€',
            'ì»¨ì„¼ì„œìŠ¤ìƒíšŒ', 'ê¹œì§ì‹¤ì ', 'ì–´ë‹ì„œí”„ë¼ì´ì¦ˆ', 'ê°€ì´ë˜ìŠ¤ìƒí–¥',
            # ì¶”ê°€ - íŠ¸ë Œë“œ
            'ëª¨ë©˜í…€', 'ëŒí’', 'ì£¼ëª©', 'ê°ê´‘', 'ì¸ê¸°', 'ê´€ì‹¬', 'ìœ ë§', 'ìœ ë ¥',
            'ì„ ë‘', '1ìœ„', 'ì ìœ ìœ¨', 'ì‹œìž¥ì§€ë°°ë ¥', 'ê²½ìŸìš°ìœ„',
            # ì¶”ê°€ - ì™¸ë¶€ ìš”ì¸
            'ì •ì±…ì§€ì›', 'ê·œì œì™„í™”', 'ë³´ì¡°ê¸ˆ', 'ìˆ˜ì¶œì¦ê°€', 'í™˜ìœ¨í˜¸ìž¬', 'ìœ ê°€í•˜ë½',
            'ê¸ˆë¦¬ì¸í•˜', 'ì–‘ì ì™„í™”', 'ê²½ê¸°íšŒë³µ', 'ê²½ê¸°í™•ìž¥'
        ]

        # ë¶€ì • í‚¤ì›Œë“œ (ëŒ€í­ í™•ìž¥ - ê¸ˆìœµ ìš©ì–´)
        self.negative_keywords = [
            # ê¸°ì¡´
            'í•˜ë½', 'ê¸‰ë½', 'ì•…ìž¬', 'ê°ì†Œ', 'í•˜í–¥', 'ì•…í™”', 'ìœ„í—˜', 'ìš°ë ¤', 'ë¶€ì§„',
            'ì•½ì„¸', 'í­ë½', 'ì†ì‹¤', 'ì ìž', 'ë¶€ì •', 'ë¦¬ìŠ¤í¬', 'í•˜ë½ì„¸', 'ë§¤ë„',
            'ê²½ê³ ', 'ì¡°ì •', 'ë§ˆì´ë„ˆìŠ¤', 'ìµœì €', 'ë¶€ë‹´', 'ìœ„ê¸°', 'ì¶©ê²©', 'ìš°ìš¸',
            # ì¶”ê°€ - ì‹¤ì /ìž¬ë¬´
            'ì˜ì—…ì†ì‹¤', 'ìˆœì†ì‹¤', 'ë§¤ì¶œê°ì†Œ', 'ìˆ˜ìµì„±ì•…í™”', 'ë§ˆì§„ì¶•ì†Œ', 'ë¶€ì±„ì¦ê°€',
            'ìžì‚°ê°ì†Œ', 'í˜„ê¸ˆë¶€ì¡±', 'ìœ ë™ì„±ìœ„ê¸°', 'ìž¬ë¬´ì•…í™”', 'ì ìžì „í™˜',
            # ì¶”ê°€ - ì‹œìž¥/ê²½ì˜
            'ë¦¬ì½œ', 'ê²°í•¨', 'ë¶ˆëŸ‰', 'ì†Œì†¡', 'ë¶„ìŸ', 'ë°°ìƒ', 'ê³¼ì§•ê¸ˆ', 'ì œìž¬',
            'ê·œì œê°•í™”', 'ì¸í—ˆê°€ì·¨ì†Œ', 'ì‚¬ì—…ì² ìˆ˜', 'êµ¬ì¡°ì¡°ì •', 'ì¸ë ¥ê°ì¶•', 'íì—…',
            # ì¶”ê°€ - ì „ë§/ë¶„ì„
            'ëª©í‘œê°€í•˜í–¥', 'ë ˆì´íŒ…í•˜í–¥', 'SELL', 'ë§¤ë„ì¶”ì²œ', 'ë¹„ì¤‘ì¶•ì†Œ', 'íˆ¬ìžì˜ê²¬í•˜í–¥',
            'ì»¨ì„¼ì„œìŠ¤í•˜íšŒ', 'ì–´ë‹ì‡¼í¬', 'ê°€ì´ë˜ìŠ¤í•˜í–¥', 'ì‹¤ë§', 'ë¶€ì§„',
            # ì¶”ê°€ - ë¦¬ìŠ¤í¬
            'ì±„ë¬´ë¶ˆì´í–‰', 'ë””í´íŠ¸', 'íŒŒì‚°', 'íšŒìƒì ˆì°¨', 'ì²­ì‚°', 'ë¶€ë„', 'ì—°ì²´',
            'ì‹ ìš©ë“±ê¸‰í•˜ë½', 'íˆ¬ìžê²½ê³ ', 'ê°ë¦¬', 'íš¡ë ¹', 'ë°°ìž„', 'ë¶„ì‹íšŒê³„',
            # ì¶”ê°€ - ì™¸ë¶€ ìš”ì¸
            'ë¬´ì—­ì „ìŸ', 'ê´€ì„¸', 'ìˆ˜ì¶œê·œì œ', 'ë³´ë³µ', 'ì œìž¬', 'ë¶ˆí™•ì‹¤ì„±', 'ì§€ì •í•™',
            'ê²½ê¸°ì¹¨ì²´', 'ê²½ê¸°í›„í‡´', 'ê¸ˆë¦¬ì¸ìƒ', 'ê¸´ì¶•', 'ìœ ê°€ê¸‰ë“±', 'í™˜ìœ¨ì•…í™”'
        ]

        # ì¤‘ë¦½ í‚¤ì›Œë“œ
        self.neutral_keywords = [
            'ë³´í•©', 'íš¡ë³´', 'ê´€ë§', 'ì¤‘ë¦½', 'ë³€ë™', 'ì˜ˆìƒ', 'ì „ë§', 'ë¶„ì„', 'í‰ê°€',
            'ë°œí‘œ', 'ê³µì‹œ', 'ë³´ê³ ', 'ì„¤ëª…', 'íšŒì˜', 'ê²°ì •', 'ìœ ì§€', 'ë™ê²°'
        ]

    def analyze_text(self, text):
        """
        í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„

        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸

        Returns:
            dict: ê°ì„± ì ìˆ˜ ë° ë¶„ë¥˜
        """
        if not text:
            return {
                'score': 0.5,
                'sentiment': 'neutral',
                'confidence': 0
            }

        text = text.lower()

        # í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        positive_count = sum(1 for keyword in self.positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in self.negative_keywords if keyword in text)
        total_count = positive_count + negative_count

        if total_count == 0:
            return {
                'score': 0.5,
                'sentiment': 'neutral',
                'confidence': 0,
                'positive_count': 0,
                'negative_count': 0
            }

        # ê°ì„± ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
        score = positive_count / total_count

        # ê°ì„± ë¶„ë¥˜
        if score >= 0.6:
            sentiment = 'positive'
        elif score <= 0.4:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'

        # ì‹ ë¢°ë„ (í‚¤ì›Œë“œ ê°œìˆ˜ì— ë¹„ë¡€)
        confidence = min(total_count / 5.0, 1.0)  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ

        return {
            'score': score,
            'sentiment': sentiment,
            'confidence': confidence,
            'positive_count': positive_count,
            'negative_count': negative_count
        }

    def analyze_news_list(self, news_list):
        """
        ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì „ì²´ ê°ì„± ë¶„ì„

        Args:
            news_list (list): ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸

        Returns:
            dict: ì¢…í•© ê°ì„± ë¶„ì„ ê²°ê³¼
        """
        if not news_list:
            return {
                'overall_score': 0.5,
                'overall_sentiment': 'neutral',
                'positive_ratio': 0,
                'negative_ratio': 0,
                'neutral_ratio': 0,
                'positive_count': 0,  # Phase 2-2: ì¶”ê°€
                'negative_count': 0,  # Phase 2-2: ì¶”ê°€
                'neutral_count': 0,   # Phase 2-2: ì¶”ê°€
                'total_news': 0,
                'confidence': 0
            }

        print(f"ðŸ“° ë‰´ìŠ¤ {len(news_list)}ê°œ ê°ì„± ë¶„ì„ ì¤‘...")

        sentiments = []
        for news in news_list:
            # ì œëª©ê³¼ ì„¤ëª… ê²°í•©
            text = f"{news.get('ì œëª©', '')} {news.get('ì„¤ëª…', '')}"
            result = self.analyze_text(text)
            sentiments.append(result)

        # í†µê³„ ê³„ì‚°
        total = len(sentiments)
        positive = sum(1 for s in sentiments if s['sentiment'] == 'positive')
        negative = sum(1 for s in sentiments if s['sentiment'] == 'negative')
        neutral = total - positive - negative

        # ì „ì²´ ê°ì„± ì ìˆ˜ (í‰ê· )
        overall_score = sum(s['score'] for s in sentiments) / total
        overall_confidence = sum(s['confidence'] for s in sentiments) / total

        # ì „ì²´ ê°ì„± ë¶„ë¥˜
        if overall_score >= 0.6:
            overall_sentiment = 'positive'
        elif overall_score <= 0.4:
            overall_sentiment = 'negative'
        else:
            overall_sentiment = 'neutral'

        result = {
            'overall_score': overall_score,
            'overall_sentiment': overall_sentiment,
            'positive_ratio': positive / total,
            'negative_ratio': negative / total,
            'neutral_ratio': neutral / total,
            'positive_count': positive,
            'negative_count': negative,
            'neutral_count': neutral,
            'total_news': total,
            'confidence': overall_confidence,
            'details': sentiments
        }

        print(f"âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ: {overall_sentiment} (ì ìˆ˜: {overall_score:.2f})")
        return result

    def get_sentiment_trend(self, news_list, days=7):
        """
        ì‹œê°„ë³„ ê°ì„± ì¶”ì„¸ ë¶„ì„

        Args:
            news_list (list): ë‚ ì§œ ì •ë³´ê°€ ìžˆëŠ” ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            days (int): ë¶„ì„ ê¸°ê°„

        Returns:
            dict: ì¼ë³„ ê°ì„± ì¶”ì„¸
        """
        from datetime import datetime, timedelta
        from collections import defaultdict

        daily_sentiments = defaultdict(list)

        for news in news_list:
            pub_date = news.get('ê²Œì‹œì¼')
            if not pub_date:
                continue

            try:
                # ISO í˜•ì‹ íŒŒì‹±
                date = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                day_key = date.strftime('%Y-%m-%d')

                text = f"{news.get('ì œëª©', '')} {news.get('ì„¤ëª…', '')}"
                sentiment = self.analyze_text(text)
                daily_sentiments[day_key].append(sentiment['score'])
            except:
                continue

        # ì¼ë³„ í‰ê·  ê³„ì‚°
        trend = {}
        for day, scores in sorted(daily_sentiments.items()):
            if scores:
                trend[day] = {
                    'score': sum(scores) / len(scores),
                    'count': len(scores)
                }

        return trend


# ê³ ê¸‰ AI ê°ì„± ë¶„ì„ (transformers ì‚¬ìš© - ì„ íƒì‚¬í•­)
class AdvancedSentimentAnalyzer:
    """
    Transformer ê¸°ë°˜ ê³ ê¸‰ ê°ì„± ë¶„ì„
    ì´ˆê¸° ë¡œë”©ì— ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ ì„ íƒì  ì‚¬ìš©
    """

    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.loaded = False

    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ (ì²˜ìŒ í•œ ë²ˆë§Œ)"""
        try:
            from transformers import AutoTokenizer, AutoModelForSequenceClassification
            import torch

            print("ðŸ¤– AI ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘... (ìµœì´ˆ 1íšŒ, ìˆ˜ ë¶„ ì†Œìš”)")

            model_name = "cardiffnlp/twitter-roberta-base-sentiment"
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_name)

            self.loaded = True
            print("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return True

        except ImportError:
            print("âš ï¸ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install transformers torch")
            return False
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

    def analyze_text(self, text):
        """AI ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        if not self.loaded:
            if not self.load_model():
                return None

        try:
            import torch

            inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
            outputs = self.model(**inputs)
            scores = torch.nn.functional.softmax(outputs.logits, dim=1)

            # ë ˆì´ë¸”: 0=negative, 1=neutral, 2=positive
            labels = ['negative', 'neutral', 'positive']
            scores_dict = {labels[i]: scores[0][i].item() for i in range(3)}

            # ìµœê³  ì ìˆ˜ ë ˆì´ë¸”
            max_label = max(scores_dict, key=scores_dict.get)

            return {
                'sentiment': max_label,
                'scores': scores_dict,
                'confidence': scores_dict[max_label]
            }

        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    analyzer = SentimentAnalyzer()

    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_texts = [
        "ì‚¼ì„±ì „ìž ì£¼ê°€ ê¸‰ë“±, ë°˜ë„ì²´ ìˆ˜ì¶œ í˜¸ì¡°",
        "ì¦ì‹œ í­ë½, íˆ¬ìžìžë“¤ ìš°ë ¤ í™•ì‚°",
        "ì½”ìŠ¤í”¼ ë³´í•©ê¶Œì—ì„œ ë“±ë½ ë°˜ë³µ",
        "ë¹„íŠ¸ì½”ì¸ ì‹ ê³ ê°€ ê²½ì‹ , íˆ¬ìž ì—´ê¸° ëœ¨ê±°ì›Œ",
        "ì•”í˜¸í™”í ì‹œìž¥ ê¸‰ë½, ê·œì œ ë¦¬ìŠ¤í¬ ë¶€ê°"
    ]

    print("=== ê°œë³„ í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ ===")
    for text in test_texts:
        result = analyzer.analyze_text(text)
        print(f"\ní…ìŠ¤íŠ¸: {text}")
        print(f"ê°ì„±: {result['sentiment']} (ì ìˆ˜: {result['score']:.2f}, ì‹ ë¢°ë„: {result['confidence']:.2f})")

    # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë¶„ì„
    print("\n\n=== ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¢…í•© ë¶„ì„ ===")
    news_list = [{'ì œëª©': text, 'ì„¤ëª…': ''} for text in test_texts]
    overall = analyzer.analyze_news_list(news_list)

    print(f"\nì¢…í•© ê°ì„±: {overall['overall_sentiment']}")
    print(f"ì ìˆ˜: {overall['overall_score']:.2f}")
    print(f"ê¸ì •: {overall['positive_ratio']:.1%}")
    print(f"ë¶€ì •: {overall['negative_ratio']:.1%}")
    print(f"ì¤‘ë¦½: {overall['neutral_ratio']:.1%}")
